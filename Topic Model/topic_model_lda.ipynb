{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxLzbP1sG14Y"
      },
      "source": [
        "## Etape 1 : Importation du dataset\n",
        "\n",
        "###Le dataset utilisé est importé de la librairie sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gwTRYVWHG14Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "newsgroups = fetch_20newsgroups(shuffle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBhW8giIG14Z"
      },
      "source": [
        "### Les articles sont déjà regroupés en 20 sujets différents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBQkYwaoG14Z",
        "outputId": "024d8562-80ee-43fa-be9a-cce750f9c26b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
          ]
        }
      ],
      "source": [
        "print(list(newsgroups.target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmG13qL_IX7V"
      },
      "source": [
        "### Exemple d'article de notre dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "eomwaQEAG14a",
        "outputId": "3c499a8f-ff1e-401b-e896-45ea1c33c260"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'From: david@terminus.ericsson.se (David Bold)\\nSubject: Re: Question for those with popular morality\\nReply-To: david@terminus.ericsson.se\\nDistribution: world\\nOrganization: Camtec Electronics (Ericsson), Leicester, England\\nLines: 77\\nNntp-Posting-Host: bangkok\\n\\nIn article 17570@freenet.carleton.ca, ad354@Freenet.carleton.ca (James Owens) writes:\\n>\\n>In a previous article, david@terminus.ericsson.se (David Bold) says:\\n>\\n>>\\n>>I don\\'t mean to be rude, but I think that you\\'ve got hold of the wrong\\n>>end of a different stick...\\n>>\\n>>David\\n>\\n>I had a look at your posting again and I see what you mean!  I was so\\n>intent on explaining how Jung thought we could be more moral than God that\\n>I overlooked your main line of thought.\\n>\\n>You seem to be saying that, God being unknowable, His morality is unknowable.\\n\\nYep, that\\'s pretty much it. I\\'m not a Jew but I understand that this is the\\nJewish way of thinking. However, the Jews believe that the Covenant between\\nYHWH and the Patriarchs (Abraham and Moses, in this case) establishes a Moral\\nCode to follow for mankind. Even the Jews could not decide where the boundaries\\nfall, though.\\n\\nAs I understand it, the Sadducees believed that the Torah was all that was\\nrequired, whereas the Pharisees (the ancestors of modern Judaism) believed that\\nthe Torah was available for interpretation to lead to an understanding of\\nthe required Morality in all its nuances (->Talmud).\\n\\nThe essence of all of this is that Biblical Morality is an interface between\\nMan and YHWH (for a Jew or Christian) and does not necessarily indicate\\nanything about YHWH outside of that relationship (although one can speculate).\\n\\n>\\n>The first thing that comes to mind is that man is supposed to be created\\n>in His image, so there is an argument that we are committed to whatever\\n>moral code He follows as part of trying to live up to that image.  If we\\n>are supposed to live by Christ\\'s example, you would be hard pressed to\\n>argue that God is a \"do what I say, not what I do\" kind of guy.\\n\\nThe trouble with all of this is that we don\\'t really know what the \"created\\nin His image\" means. I\\'ve heard a number of different opinions on this and\\nhave still not come to any conclusion. This rather upsets the Apple Cart if\\none wants to base a Life Script on this shaky foundation (to mix metaphors\\nunashamedly!) As to living by Christ\\'s example, we know very little about\\nJesus as a person. We only have his recorded utterances in a set of narratives\\nby his followers, and some very small references from comtemporary historians.\\nRevelation aside, one can only \"know\" Christ second-hand or worse.\\n\\nThis is not an attempt to debunk Christianity (although it may seem that way\\ninitially), the point I`m trying to make is that we only really have the Bible\\nto interpret, and that interpretation is by humanity. I guess this is where\\nFaith or Relevation comes in with all its inherent subjectiveness.\\n\\n>\\n>Metaphysically, if there are multiple moral codes then there is no\\n>Absolute moral code, and I think this is theologically questionable.\\n\\nNo. There may be an absolute moral code. There are undoubtably multiple\\nmoral codes. The multiple moral codes may be founded in the absolute moral\\ncode. As an example, a parent may tell a child never to swear, and the child\\nmay assume that the parent never swears simply because the parent has told\\nthe child that it is \"wrong\". Now, the parent may swear like a trooper in\\nthe pub or bar (where there are no children). The \"wrongness\" here is if\\nthe child disobeys the parent. The parent may feel that it is \"inappropriate\"\\nto swear in front of children but may be quite happy to swear in front of\\nanimals. The analogy does not quite hold water because the child knows that\\nhe is of the same type as the parent (and may be a parent later in life) but\\nyou get the gist of it? Incidentally, the young child considers the directive\\nas absolute until he gets older (see Piaget) and learns a morality of his own.\\n\\nDavid.\\n\\n---\\nOn religion:\\n\\n\"Oh, where is the sea?\", the fishes cried,\\nAs they swam its clearness through.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "newsgroups.data[11]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI35_ROUG14a"
      },
      "source": [
        "## Etape 2 : Data Preprocessing \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDBwFmlNIquA"
      },
      "source": [
        "### Importation des modules nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c1F9Zwjtw_G0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "45yEBu_GG14a"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itBG1ZBdG14b",
        "outputId": "adeff067-e8e0-46f6-9da5-64baf6ff5852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSNQ7mNeJD8F"
      },
      "source": [
        "### Fonction de preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XRF2DwuqG14c"
      },
      "outputs": [],
      "source": [
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "def lemmatize_stemming(text) :\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='n'))\n",
        "\n",
        "def preprocess(text) :\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text) :\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3 :\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WwdpgxHJKix"
      },
      "source": [
        "### Exemple de preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqnTD5BcG14c",
        "outputId": "58d27ad4-3ebf-4b8a-96ef-5f8b1eea424b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original document : \n",
            "['I', 'really', 'like', 'using', 'Python', 'for', 'topic', 'modeling.', 'Thank', 'you', 'for', 'the', 'internship', '!']\n",
            "\n",
            "Tokenized and lemmatized document: \n",
            "['like', 'python', 'topic', 'model', 'thank', 'internship']\n"
          ]
        }
      ],
      "source": [
        "doc_sample = 'I really like using Python for topic modeling. Thank you for the internship !'\n",
        "\n",
        "print(\"Original document : \")\n",
        "words = []\n",
        "for word in doc_sample.split(' ') :\n",
        "    words.append(word)\n",
        "print(words)\n",
        "\n",
        "print(\"\\nTokenized and lemmatized document: \")\n",
        "print(preprocess(doc_sample))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hsT0uHXG14c"
      },
      "source": [
        "### Preprocessing du dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opq16ENoG14c",
        "outputId": "a6c90d79-8df4-4c61-8fb0-d1c77c2d53d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['david', 'terminus', 'ericsson', 'david', 'bold', 'subject', 'question', 'popular', 'moral', 'repli', 'david', 'terminus', 'ericsson', 'distribut', 'world', 'organ', 'camtec', 'electron', 'ericsson', 'leicest', 'england', 'line', 'nntp', 'post', 'host', 'bangkok', 'articl', 'freenet', 'carleton', 'freenet', 'carleton', 'jame', 'owen', 'write', 'previous', 'articl', 'david', 'terminus', 'ericsson', 'david', 'bold', 'say', 'mean', 'rude', 'think', 'hold', 'wrong', 'differ', 'stick', 'david', 'look', 'post', 'mean', 'intent', 'explain', 'jung', 'thought', 'moral', 'overlook', 'main', 'line', 'thought', 'say', 'unknow', 'moral', 'unknow', 'pretti', 'understand', 'jewish', 'think', 'jew', 'believ', 'coven', 'yhwh', 'patriarch', 'abraham', 'mose', 'case', 'establish', 'moral', 'code', 'follow', 'mankind', 'jew', 'decid', 'boundari', 'fall', 'understand', 'sadduce', 'believ', 'torah', 'requir', 'pharise', 'ancestor', 'modern', 'judaism', 'believ', 'torah', 'avail', 'interpret', 'lead', 'understand', 'requir', 'moral', 'nuanc', 'talmud', 'essenc', 'biblic', 'moral', 'interfac', 'yhwh', 'christian', 'necessarili', 'indic', 'yhwh', 'outsid', 'relationship', 'specul', 'thing', 'come', 'mind', 'suppos', 'creat', 'imag', 'argument', 'commit', 'moral', 'code', 'follow', 'tri', 'live', 'imag', 'suppos', 'live', 'christ', 'exampl', 'hard', 'press', 'argu', 'kind', 'troubl', 'know', 'creat', 'imag', 'mean', 'heard', 'number', 'differ', 'opinion', 'come', 'conclus', 'upset', 'appl', 'cart', 'want', 'base', 'life', 'script', 'shaki', 'foundat', 'metaphor', 'unasham', 'live', 'christ', 'exampl', 'know', 'littl', 'jesus', 'person', 'record', 'utter', 'narrat', 'follow', 'small', 'refer', 'comtemporari', 'historian', 'revel', 'asid', 'know', 'christ', 'second', 'hand', 'wors', 'attempt', 'debunk', 'christian', 'initi', 'point', 'tri', 'bibl', 'interpret', 'interpret', 'human', 'guess', 'faith', 'relev', 'come', 'inher', 'subject', 'metaphys', 'multipl', 'moral', 'code', 'absolut', 'moral', 'code', 'think', 'theolog', 'question', 'absolut', 'moral', 'code', 'undoubt', 'multipl', 'moral', 'code', 'multipl', 'moral', 'code', 'found', 'absolut', 'moral', 'code', 'exampl', 'parent', 'tell', 'child', 'swear', 'child', 'assum', 'parent', 'swear', 'simpli', 'parent', 'told', 'child', 'wrong', 'parent', 'swear', 'like', 'trooper', 'child', 'wrong', 'child', 'disobey', 'parent', 'parent', 'feel', 'inappropri', 'swear', 'child', 'happi', 'swear', 'anim', 'analog', 'hold', 'water', 'child', 'know', 'type', 'parent', 'parent', 'later', 'life', 'gist', 'incident', 'young', 'child', 'consid', 'direct', 'absolut', 'get', 'older', 'piaget', 'learn', 'moral', 'david', 'religion', 'fish', 'cri', 'swam', 'clear']\n"
          ]
        }
      ],
      "source": [
        "processed_docs = []\n",
        "\n",
        "for doc in newsgroups.data :\n",
        "    processed_docs.append(preprocess(doc))\n",
        "\n",
        "print(processed_docs[11])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zXBnsyeG14d"
      },
      "source": [
        "## Etape 3 : Stockage des mots de notre dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o97PxqPsMPjK"
      },
      "source": [
        "### Création d'un dictionnaire qui contiendra le nombre d'occurrences de chaque mot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NYrnt3ofG14d"
      },
      "outputs": [],
      "source": [
        "dictionary = gensim.corpora.Dictionary(processed_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtTPBUGiG14e"
      },
      "source": [
        "### Filtrage de notre dictionnaire\n",
        "\n",
        "* on supprime les mots trop rares qui appraîssent moins de 15 fois\n",
        "* on supprime les mots trop fréquents qui apparaîssent dans plus de 10% des documents\n",
        "* à la fin on ne garde que les 100 000 mots les plus fréquents "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cX7frpZ-G14e"
      },
      "outputs": [],
      "source": [
        "dictionary.filter_extremes(no_below=15, no_above=0.1, keep_n=100000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLf90gzFG14e"
      },
      "source": [
        "### Conversion des documents en couple mot et nombres d'occurrences (bag-of-words format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FQmlAS7XG14e"
      },
      "outputs": [],
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3yvnM3IO2QD"
      },
      "source": [
        "### Preview du bag-of-words de notre dataset preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBYjPqE9G14e",
        "outputId": "750a014b-c27a-4339-94be-1be61759d1e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 20 (\"small\") appears 1 time.\n",
            "Word 28 (\"base\") appears 1 time.\n",
            "Word 86 (\"feel\") appears 1 time.\n",
            "Word 91 (\"heard\") appears 1 time.\n",
            "Word 97 (\"life\") appears 2 time.\n",
            "Word 103 (\"opinion\") appears 1 time.\n",
            "Word 125 (\"suppos\") appears 2 time.\n",
            "Word 152 (\"pretti\") appears 1 time.\n",
            "Word 153 (\"requir\") appears 2 time.\n",
            "Word 171 (\"clear\") appears 1 time.\n",
            "Word 172 (\"code\") appears 8 time.\n",
            "Word 190 (\"previous\") appears 1 time.\n",
            "Word 196 (\"understand\") appears 3 time.\n",
            "Word 208 (\"argument\") appears 1 time.\n",
            "Word 216 (\"consid\") appears 1 time.\n",
            "Word 233 (\"hand\") appears 1 time.\n",
            "Word 235 (\"hard\") appears 1 time.\n",
            "Word 243 (\"later\") appears 1 time.\n",
            "Word 249 (\"modern\") appears 1 time.\n",
            "Word 267 (\"second\") appears 1 time.\n",
            "Word 292 (\"direct\") appears 1 time.\n",
            "Word 305 (\"thought\") appears 2 time.\n",
            "Word 310 (\"appl\") appears 1 time.\n",
            "Word 312 (\"avail\") appears 1 time.\n",
            "Word 333 (\"interfac\") appears 1 time.\n",
            "Word 347 (\"refer\") appears 1 time.\n",
            "Word 403 (\"troubl\") appears 1 time.\n",
            "Word 409 (\"wrong\") appears 3 time.\n",
            "Word 431 (\"abraham\") appears 1 time.\n",
            "Word 432 (\"absolut\") appears 4 time.\n",
            "Word 433 (\"analog\") appears 1 time.\n",
            "Word 434 (\"ancestor\") appears 1 time.\n",
            "Word 435 (\"anim\") appears 1 time.\n",
            "Word 436 (\"argu\") appears 1 time.\n",
            "Word 437 (\"asid\") appears 1 time.\n",
            "Word 438 (\"assum\") appears 1 time.\n",
            "Word 439 (\"attempt\") appears 1 time.\n",
            "Word 440 (\"bibl\") appears 1 time.\n",
            "Word 441 (\"biblic\") appears 1 time.\n",
            "Word 442 (\"bold\") appears 2 time.\n",
            "Word 443 (\"boundari\") appears 1 time.\n",
            "Word 444 (\"carleton\") appears 2 time.\n",
            "Word 445 (\"cart\") appears 1 time.\n",
            "Word 446 (\"child\") appears 8 time.\n",
            "Word 447 (\"christ\") appears 3 time.\n",
            "Word 448 (\"christian\") appears 2 time.\n",
            "Word 449 (\"commit\") appears 1 time.\n",
            "Word 450 (\"conclus\") appears 1 time.\n",
            "Word 451 (\"coven\") appears 1 time.\n",
            "Word 452 (\"creat\") appears 2 time.\n",
            "Word 453 (\"cri\") appears 1 time.\n",
            "Word 454 (\"david\") appears 7 time.\n",
            "Word 455 (\"debunk\") appears 1 time.\n",
            "Word 456 (\"decid\") appears 1 time.\n",
            "Word 457 (\"disobey\") appears 1 time.\n",
            "Word 458 (\"electron\") appears 1 time.\n",
            "Word 459 (\"england\") appears 1 time.\n",
            "Word 460 (\"ericsson\") appears 4 time.\n",
            "Word 461 (\"essenc\") appears 1 time.\n",
            "Word 462 (\"establish\") appears 1 time.\n",
            "Word 463 (\"exampl\") appears 3 time.\n",
            "Word 464 (\"explain\") appears 1 time.\n",
            "Word 465 (\"faith\") appears 1 time.\n",
            "Word 466 (\"fall\") appears 1 time.\n",
            "Word 467 (\"fish\") appears 1 time.\n",
            "Word 468 (\"found\") appears 1 time.\n",
            "Word 469 (\"foundat\") appears 1 time.\n",
            "Word 470 (\"freenet\") appears 2 time.\n",
            "Word 471 (\"get\") appears 1 time.\n",
            "Word 472 (\"guess\") appears 1 time.\n",
            "Word 473 (\"happi\") appears 1 time.\n",
            "Word 474 (\"historian\") appears 1 time.\n",
            "Word 475 (\"hold\") appears 2 time.\n",
            "Word 476 (\"human\") appears 1 time.\n",
            "Word 477 (\"imag\") appears 3 time.\n",
            "Word 478 (\"inappropri\") appears 1 time.\n",
            "Word 479 (\"incident\") appears 1 time.\n",
            "Word 480 (\"indic\") appears 1 time.\n",
            "Word 481 (\"inher\") appears 1 time.\n",
            "Word 482 (\"initi\") appears 1 time.\n",
            "Word 483 (\"intent\") appears 1 time.\n",
            "Word 484 (\"interpret\") appears 3 time.\n",
            "Word 485 (\"jame\") appears 1 time.\n",
            "Word 486 (\"jesus\") appears 1 time.\n",
            "Word 487 (\"jew\") appears 2 time.\n",
            "Word 488 (\"jewish\") appears 1 time.\n",
            "Word 489 (\"judaism\") appears 1 time.\n",
            "Word 490 (\"kind\") appears 1 time.\n",
            "Word 491 (\"lead\") appears 1 time.\n",
            "Word 492 (\"learn\") appears 1 time.\n",
            "Word 493 (\"littl\") appears 1 time.\n",
            "Word 494 (\"live\") appears 3 time.\n",
            "Word 495 (\"main\") appears 1 time.\n",
            "Word 496 (\"mankind\") appears 1 time.\n",
            "Word 497 (\"metaphor\") appears 1 time.\n",
            "Word 498 (\"metaphys\") appears 1 time.\n",
            "Word 499 (\"mind\") appears 1 time.\n",
            "Word 500 (\"moral\") appears 14 time.\n",
            "Word 501 (\"mose\") appears 1 time.\n",
            "Word 502 (\"multipl\") appears 3 time.\n",
            "Word 503 (\"narrat\") appears 1 time.\n",
            "Word 504 (\"necessarili\") appears 1 time.\n",
            "Word 505 (\"older\") appears 1 time.\n",
            "Word 506 (\"outsid\") appears 1 time.\n",
            "Word 507 (\"overlook\") appears 1 time.\n",
            "Word 508 (\"owen\") appears 1 time.\n",
            "Word 509 (\"parent\") appears 8 time.\n",
            "Word 510 (\"popular\") appears 1 time.\n",
            "Word 511 (\"press\") appears 1 time.\n",
            "Word 512 (\"record\") appears 1 time.\n",
            "Word 513 (\"relationship\") appears 1 time.\n",
            "Word 514 (\"relev\") appears 1 time.\n",
            "Word 515 (\"religion\") appears 1 time.\n",
            "Word 516 (\"revel\") appears 1 time.\n",
            "Word 517 (\"rude\") appears 1 time.\n",
            "Word 518 (\"script\") appears 1 time.\n",
            "Word 519 (\"simpli\") appears 1 time.\n",
            "Word 520 (\"specul\") appears 1 time.\n",
            "Word 521 (\"stick\") appears 1 time.\n",
            "Word 522 (\"swear\") appears 5 time.\n",
            "Word 523 (\"theolog\") appears 1 time.\n",
            "Word 524 (\"told\") appears 1 time.\n",
            "Word 525 (\"torah\") appears 2 time.\n",
            "Word 526 (\"type\") appears 1 time.\n",
            "Word 527 (\"undoubt\") appears 1 time.\n",
            "Word 528 (\"upset\") appears 1 time.\n",
            "Word 529 (\"utter\") appears 1 time.\n",
            "Word 530 (\"water\") appears 1 time.\n",
            "Word 531 (\"wors\") appears 1 time.\n",
            "Word 532 (\"young\") appears 1 time.\n"
          ]
        }
      ],
      "source": [
        "bow_doc_x = bow_corpus[11]\n",
        "\n",
        "for i in range(len(bow_doc_x)) :\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], dictionary[bow_doc_x[i][0]], bow_doc_x[i][1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejoUG_0YG14e"
      },
      "source": [
        "## Etape 4 : Exécution du LDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHHimPQ4Sdbr"
      },
      "source": [
        "### On entraîne notre modèle LDA sachant que :###\n",
        "\n",
        "* LdaMulticore pour utiliser tout les coeurs du CPU afin de gagner en temps d'exécution\n",
        "\n",
        "* num_topics : nombre de topic à extraire du corpus\n",
        "\n",
        "* id2word : mapping des identifiants de mots (entiers) aux mots (chaînes de caractères)\n",
        "\n",
        "* passes : nombre de passage d'entraînement dans le corpus\n",
        "\n",
        "* workers : nombre de coeurs à utiliser (par défaut tous les coeurs disponibles)\n",
        "\n",
        "* alpha : rareté de la distribution document-topic\n",
        "\n",
        "  - alpha grand = chaque document contient un mélange de tous les sujets\n",
        "    - les documents semblent similaires les uns aux autres\n",
        "  - alpha petit = chaque document contient un mélange de très peu de sujets\n",
        "\n",
        "* eta : rareté de la distribution topic-word\n",
        "\n",
        "  - eta grand = chaque sujet contient un mélange de la plupart des mots\n",
        "    - les sujets semblent similaires les uns aux autres\n",
        "  - eta petit = chaque sujet contient un mélange de quelques mots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "I3u4RKCqG14f"
      },
      "outputs": [],
      "source": [
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics = 8, id2word = dictionary, passes = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKMEXuOsP9Qj"
      },
      "source": [
        "### Pour chaque topic on va analyser le nombre d'occurrences de chaque mot et son poids relatif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzG5Rrd7G14f"
      },
      "outputs": [],
      "source": [
        "topics = []\n",
        "for idx, topic in lda_model.print_topics(-1) :\n",
        "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
        "    print(\"\\n\")\n",
        "    topics.append(topic)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## On stocke les résultats de notre topic modeling"
      ],
      "metadata": {
        "id": "WaEW3VpsOoVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "5Qovd9PlOy8q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_topic_model = []\n",
        "for i in range(len(topics)):\n",
        "  str = topics[i].split(' + ')\n",
        "  topic_model = []\n",
        "  for j in range(10):\n",
        "    weight = str[j][0:5]\n",
        "    word = str[j][7:len(str[j])-1]\n",
        "    topic_model.append((weight, word))\n",
        "  all_topic_model.append(topic_model)"
      ],
      "metadata": {
        "id": "0a1_RtNaOsyl"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_topic_model = pd.DataFrame(all_topic_model)\n",
        "df_topic_model.rename(index = {0: \"Topic 1\", 1: \"Topic 2\", 2: \"Topic 3\", 3: \"Topic 4\", 4: \"Topic 5\", 5: \"Topic 6\", 6: \"Topic 7\", 7: \"Topic 8\"}, inplace = True)\n",
        "df_topic_model.rename(columns = {0: 'Word 1', 1: 'Word 2', 2: 'Word 3', 3: 'Word 4', 4: 'Word 5', 5: 'Word 6', 6: 'Word 7', 7: 'Word 8', 8: 'Word 9', 9: 'Word 10'}, inplace = True)"
      ],
      "metadata": {
        "id": "gfENCX03RrJ5"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_topic_model.to_csv('topic_model.csv')"
      ],
      "metadata": {
        "id": "z4cyo3lbTcIV"
      },
      "execution_count": 78,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "topic_model_lda.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}