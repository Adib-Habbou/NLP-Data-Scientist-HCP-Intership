{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLrDu5u3zpob"
      },
      "source": [
        "# Web Scraping Le Matin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIK381tTDH_I"
      },
      "source": [
        "## Installation du package selenium et du chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbsYCJbHCwfT"
      },
      "outputs": [],
      "source": [
        "# installation du package selenium\n",
        "!pip install selenium\n",
        "# installation du chormedriver\n",
        "!apt install chromium-chromedriver\n",
        "# copie du chromedriver\n",
        "!cp C:\\Users\\Adib\\Documents\\Stage\\Stage 1A\\Selenium Practice\\chromedriver.exe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoNBCjkJDKUT"
      },
      "source": [
        "## Importation des librairies nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c_DQ5uDwDKBz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from selenium import webdriver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vy-mzxSDONl"
      },
      "source": [
        "## Modification des options du chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "albJpmVsDP5O"
      },
      "outputs": [],
      "source": [
        "# options chromedriver pour l'utiliser dans un notebook\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('-headless')\n",
        "options.add_argument('-no-sandbox')\n",
        "options.add_argument('-disable-dev-shm-usage')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoGO95JnDROf"
      },
      "source": [
        "## Instanciation du WebDriver de Chrome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DQTwuGxXDTIF"
      },
      "outputs": [],
      "source": [
        "# création de l'instance WebDriver de Chrome\n",
        "driver = webdriver.Chrome('chromedriver', options=options)\n",
        "# lien du site Le Matin\n",
        "website = 'https://lematin.ma/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLUDaQtnDfYL"
      },
      "source": [
        "## Liste des catégories du site"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g1LNI1WHDgsB"
      },
      "outputs": [],
      "source": [
        "# catégories du site Le Matin\n",
        "categories = ['activites-royales', 'nation', 'economie', 'monde', 'societe', 'culture', 'regions', 'emploi', 'sports', 'automobile']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVZsnUhMD4XO"
      },
      "source": [
        "## Récupération des liens d'articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BNmj53I9D7nS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2590f01-ae69-49e9-f5b7-caa258ba201b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\n",
            "  del sys.path[0]\n"
          ]
        }
      ],
      "source": [
        "# liste des liens vers les articles\n",
        "articles_links = []\n",
        "# parcours des catégories\n",
        "for category in categories:\n",
        "  category_link = website + 'journal/' + category\n",
        "  # parcours des pages de chaque catégorie\n",
        "  page_number = 0\n",
        "  while (page_number < 40):\n",
        "    webpage_link = category_link + '/' + str(page_number)\n",
        "    page_number += 1\n",
        "    # parcours des articles de chaque page\n",
        "    driver.get(webpage_link)\n",
        "    href_links = driver.find_elements_by_xpath('//div/div/div/div/a[@href]')\n",
        "    for href_link in href_links:\n",
        "      articles_links.append([href_link.get_attribute(\"href\"), category])\n",
        "articles_links = list(filter(lambda article_link: 'https://lematin.ma/express' in article_link[0], articles_links))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_articles_links = pd.DataFrame(articles_links, columns = ['article link', 'category'])"
      ],
      "metadata": {
        "id": "FOUkXYlwV7i6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_articles_links.to_csv('articles_links_le_matin.csv')"
      ],
      "metadata": {
        "id": "i3aGPW6jWLrJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ceFuIu7FiJ3"
      },
      "source": [
        "## Vérification de la liste de liens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OcIzLccpFifj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b3eb8de-41c4-403a-d4bd-c2cf1777453e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['https://lematin.ma/express/2022/fortes-averses-orageuses-mardi-plusieurs-provinces/377085.html',\n",
              "  'nation'],\n",
              " ['https://lematin.ma/express/2022/bad-accorde-91-millions-deuros-financement-additionnels-maroc-renforcer-attractivite/377082.html',\n",
              "  'nation'],\n",
              " ['https://lematin.ma/express/2022/marrakech-rire-reparti/377076.html',\n",
              "  'nation'],\n",
              " ['https://lematin.ma/express/2022/covid-19-1677-cas-confirmes-1-deces-mardi/377079.html',\n",
              "  'nation'],\n",
              " ['https://lematin.ma/express/2022/hausse-cas-covid-piqure-rappel-ministre-sante/377072.html',\n",
              "  'nation']]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# affichage de 5 liens pris au hasard\n",
        "articles_links[1000:1005]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-pRjT9C7FmAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "318f3404-391b-42e8-e196-f69d033654cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12278"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# affichage du nombre total de liens\n",
        "len(articles_links)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI2MaSocLiUh"
      },
      "source": [
        "## Récupération du contenu des articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Y1YE6OAAQoCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ae5770-02af-4524-8ca9-dbe7c70b08f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "# data frame des données collectés\n",
        "df_articles = pd.DataFrame()\n",
        "# parcours des liens collectés\n",
        "for article_link in articles_links[:1000]:\n",
        "  # accès à la page de l'article\n",
        "  driver.get(article_link[0])\n",
        "  # récupération du contenu de l'article\n",
        "  content_scrap = driver.find_elements_by_xpath('//div/p')\n",
        "  content = [p.text for p in content_scrap if len(p.text) > 50]\n",
        "  content = ' '.join(content)\n",
        "  # création de la liste de nos données\n",
        "  article = {'category' : article_link[1], 'content' : content}\n",
        "  # transformation en data frame\n",
        "  df_article = pd.DataFrame(article, index = [0])\n",
        "  # transformation en data frame\n",
        "  df_articles = df_articles.append(df_article, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transformation du data frame en fichier csv\n",
        "df_articles.to_csv('le_matin_articles.csv')"
      ],
      "metadata": {
        "id": "dWg4ppE9Rj2Q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for article_link in articles_links[1000:2000]:\n",
        "  # accès à la page de l'article\n",
        "  driver.get(article_link[0])\n",
        "  # récupération du contenu de l'article\n",
        "  content_scrap = driver.find_elements_by_xpath('//div/p')\n",
        "  content = [p.text for p in content_scrap if len(p.text) > 50]\n",
        "  content = ' '.join(content)\n",
        "  # création de la liste de nos données\n",
        "  article = {'category' : article_link[1], 'content' : content}\n",
        "  # transformation en data frame\n",
        "  df_article = pd.DataFrame(article, index = [0])\n",
        "  # transformation en data frame\n",
        "  df_articles = df_articles.append(df_article, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nIuBvw1RnWh",
        "outputId": "bae69022-b654-406d-dc7f-3330690ba6ec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transformation du data frame en fichier csv\n",
        "df_articles.to_csv('le_matin_articles.csv')"
      ],
      "metadata": {
        "id": "bEYf1CtMRtFw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for article_link in articles_links[2000:3000]:\n",
        "  # accès à la page de l'article\n",
        "  driver.get(article_link[0])\n",
        "  # récupération du contenu de l'article\n",
        "  content_scrap = driver.find_elements_by_xpath('//div/p')\n",
        "  content = [p.text for p in content_scrap if len(p.text) > 50]\n",
        "  content = ' '.join(content)\n",
        "  # création de la liste de nos données\n",
        "  article = {'category' : article_link[1], 'content' : content}\n",
        "  # transformation en data frame\n",
        "  df_article = pd.DataFrame(article, index = [0])\n",
        "  # transformation en data frame\n",
        "  df_articles = df_articles.append(df_article, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_K0FY0eRtZg",
        "outputId": "ee20d735-5f9a-46b6-9f11-ad64368e7d8a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transformation du data frame en fichier csv\n",
        "df_articles.to_csv('le_matin_articles.csv')"
      ],
      "metadata": {
        "id": "r0ormLeTR_Sz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for article_link in articles_links[3000:4000]:\n",
        "  # accès à la page de l'article\n",
        "  driver.get(article_link[0])\n",
        "  # récupération du contenu de l'article\n",
        "  content_scrap = driver.find_elements_by_xpath('//div/p')\n",
        "  content = [p.text for p in content_scrap if len(p.text) > 50]\n",
        "  content = ' '.join(content)\n",
        "  # création de la liste de nos données\n",
        "  article = {'category' : article_link[1], 'content' : content}\n",
        "  # transformation en data frame\n",
        "  df_article = pd.DataFrame(article, index = [0])\n",
        "  # transformation en data frame\n",
        "  df_articles = df_articles.append(df_article, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbc188bzRv3f",
        "outputId": "96997089-97b8-455c-f1ad-68127f548581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transformation du data frame en fichier csv\n",
        "df_articles.to_csv('le_matin_articles.csv')"
      ],
      "metadata": {
        "id": "6t1kfOonR_sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for article_link in articles_links[4000:5000]:\n",
        "  # accès à la page de l'article\n",
        "  driver.get(article_link[0])\n",
        "  # récupération du contenu de l'article\n",
        "  content_scrap = driver.find_elements_by_xpath('//div/p')\n",
        "  content = [p.text for p in content_scrap if len(p.text) > 50]\n",
        "  content = ' '.join(content)\n",
        "  # création de la liste de nos données\n",
        "  article = {'category' : article_link[1], 'content' : content}\n",
        "  # transformation en data frame\n",
        "  df_article = pd.DataFrame(article, index = [0])\n",
        "  # transformation en data frame\n",
        "  df_articles = df_articles.append(df_article, ignore_index=True)"
      ],
      "metadata": {
        "id": "EuKGQdLXRxma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformation du data frame en fichier csv\n",
        "df_articles.to_csv('le_matin_articles.csv')"
      ],
      "metadata": {
        "id": "5m7gmPlASAEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for article_link in articles_links[5000:6000]:\n",
        "  # accès à la page de l'article\n",
        "  driver.get(article_link[0])\n",
        "  # récupération du contenu de l'article\n",
        "  content_scrap = driver.find_elements_by_xpath('//div/p')\n",
        "  content = [p.text for p in content_scrap if len(p.text) > 50]\n",
        "  content = ' '.join(content)\n",
        "  # création de la liste de nos données\n",
        "  article = {'category' : article_link[1], 'content' : content}\n",
        "  # transformation en data frame\n",
        "  df_article = pd.DataFrame(article, index = [0])\n",
        "  # transformation en data frame\n",
        "  df_articles = df_articles.append(df_article, ignore_index=True)"
      ],
      "metadata": {
        "id": "4s1LNi_IRzL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformation du data frame en fichier csv\n",
        "df_articles.to_csv('le_matin_articles.csv')"
      ],
      "metadata": {
        "id": "2tKJnpojSAiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for article_link in articles_links[7000:8000]:\n",
        "  # accès à la page de l'article\n",
        "  driver.get(article_link[0])\n",
        "  # récupération du contenu de l'article\n",
        "  content_scrap = driver.find_elements_by_xpath('//div/p')\n",
        "  content = [p.text for p in content_scrap if len(p.text) > 50]\n",
        "  content = ' '.join(content)\n",
        "  # création de la liste de nos données\n",
        "  article = {'category' : article_link[1], 'content' : content}\n",
        "  # transformation en data frame\n",
        "  df_article = pd.DataFrame(article, index = [0])\n",
        "  # transformation en data frame\n",
        "  df_articles = df_articles.append(df_article, ignore_index=True)"
      ],
      "metadata": {
        "id": "bID4BLgYR0-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformation du data frame en fichier csv\n",
        "df_articles.to_csv('le_matin_articles.csv')"
      ],
      "metadata": {
        "id": "4szRfINmSBCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for article_link in articles_links[9000:10000]:\n",
        "  # accès à la page de l'article\n",
        "  driver.get(article_link[0])\n",
        "  # récupération du contenu de l'article\n",
        "  content_scrap = driver.find_elements_by_xpath('//div/p')\n",
        "  content = [p.text for p in content_scrap if len(p.text) > 50]\n",
        "  content = ' '.join(content)\n",
        "  # création de la liste de nos données\n",
        "  article = {'category' : article_link[1], 'content' : content}\n",
        "  # transformation en data frame\n",
        "  df_article = pd.DataFrame(article, index = [0])\n",
        "  # transformation en data frame\n",
        "  df_articles = df_articles.append(df_article, ignore_index=True)"
      ],
      "metadata": {
        "id": "6rQIh7b1R2bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformation du data frame en fichier csv\n",
        "df_articles.to_csv('le_matin_articles.csv')"
      ],
      "metadata": {
        "id": "uOfxnwcwSBhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for article_link in articles_links[10000:11000]:\n",
        "  # accès à la page de l'article\n",
        "  driver.get(article_link[0])\n",
        "  # récupération du contenu de l'article\n",
        "  content_scrap = driver.find_elements_by_xpath('//div/p')\n",
        "  content = [p.text for p in content_scrap if len(p.text) > 50]\n",
        "  content = ' '.join(content)\n",
        "  # création de la liste de nos données\n",
        "  article = {'category' : article_link[1], 'content' : content}\n",
        "  # transformation en data frame\n",
        "  df_article = pd.DataFrame(article, index = [0])\n",
        "  # transformation en data frame\n",
        "  df_articles = df_articles.append(df_article, ignore_index=True)"
      ],
      "metadata": {
        "id": "WYUr2vDsR5Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformation du data frame en fichier csv\n",
        "df_articles.to_csv('le_matin_articles.csv')"
      ],
      "metadata": {
        "id": "sEWl99XRSCEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for article_link in articles_links[11000:12000]:\n",
        "  # accès à la page de l'article\n",
        "  driver.get(article_link[0])\n",
        "  # récupération du contenu de l'article\n",
        "  content_scrap = driver.find_elements_by_xpath('//div/p')\n",
        "  content = [p.text for p in content_scrap if len(p.text) > 50]\n",
        "  content = ' '.join(content)\n",
        "  # création de la liste de nos données\n",
        "  article = {'category' : article_link[1], 'content' : content}\n",
        "  # transformation en data frame\n",
        "  df_article = pd.DataFrame(article, index = [0])\n",
        "  # transformation en data frame\n",
        "  df_articles = df_articles.append(df_article, ignore_index=True)"
      ],
      "metadata": {
        "id": "VjwdVIbDR6zE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformation du data frame en fichier csv\n",
        "df_articles.to_csv('le_matin_articles.csv')"
      ],
      "metadata": {
        "id": "yULsSPPlaWdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for article_link in articles_links[12000:]:\n",
        "  # accès à la page de l'article\n",
        "  driver.get(article_link[0])\n",
        "  # récupération du contenu de l'article\n",
        "  content_scrap = driver.find_elements_by_xpath('//div/p')\n",
        "  content = [p.text for p in content_scrap if len(p.text) > 50]\n",
        "  content = ' '.join(content)\n",
        "  # création de la liste de nos données\n",
        "  article = {'category' : article_link[1], 'content' : content}\n",
        "  # transformation en data frame\n",
        "  df_article = pd.DataFrame(article, index = [0])\n",
        "  # transformation en data frame\n",
        "  df_articles = df_articles.append(df_article, ignore_index=True)"
      ],
      "metadata": {
        "id": "G7IsH01Macpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFigQpqgSyYD"
      },
      "source": [
        "## Vérification des données collectés"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbvZgRPnSyon"
      },
      "outputs": [],
      "source": [
        "# affichage des premières valeurs\n",
        "df_articles.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_yQRy7f7D-Y"
      },
      "outputs": [],
      "source": [
        "# rapide description du data frame\n",
        "df_articles.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAJQyd65Sz1O"
      },
      "outputs": [],
      "source": [
        "# affichage de la taille de ntore data frame\n",
        "len(df_articles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GCe3lwXS2Yb"
      },
      "source": [
        "## Conversion en fichier csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8J0HZMkRS3ee"
      },
      "outputs": [],
      "source": [
        "# transformation du data frame en fichier csv\n",
        "df_articles.to_csv('le_matin_articles.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "massive_scraping_le_matin.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}